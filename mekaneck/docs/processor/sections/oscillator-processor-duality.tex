% ============================================================================
% OSCILLATOR-PROCESSOR DUALITY
% ============================================================================

\section{Oscillator-Processor Duality}
\label{sec:duality}

\subsection{Fundamental Equivalence}

We establish the isomorphism between oscillatory systems and computational processors \citep{goldstein2002}. Consider a harmonic oscillator with displacement $x(t)$ satisfying the equation of motion
\begin{equation}
\frac{d^2 x}{dt^2} + \omega^2 x = 0
\label{eq:harmonic}
\end{equation}
where $\omega$ denotes the angular frequency. The general solution is
\begin{equation}
x(t) = A\cos(\omega t + \phi)
\label{eq:oscillator_solution}
\end{equation}
with amplitude $A$ and initial phase $\phi$.

The oscillator completes one cycle in period $T = 2\pi/\omega$. During each cycle, the system traverses a complete phase space trajectory, visiting all accessible configurations exactly once. We identify this phase space traversal with a computational operation, yielding the fundamental equivalence
\begin{equation}
\boxed{R_{\text{compute}} = \frac{\omega}{2\pi} = \frac{1}{T}}
\label{eq:duality_boxed}
\end{equation}
where $R_{\text{compute}}$ denotes the computational rate in operations per second.

This equivalence is not merely analogical \citep{feynman1982}. The information content of an oscillator state $(A, \omega, \phi)$ at time $t$ is
\begin{equation}
I(t) = \log_2 \Omega(A, \omega, \phi, t)
\label{eq:information_content}
\end{equation}
where $\Omega$ denotes the number of distinguishable microstates consistent with the macroscopic parameters. The rate of information processing is
\begin{equation}
\frac{dI}{dt} = \frac{\partial I}{\partial \phi} \frac{d\phi}{dt} = \frac{\partial I}{\partial \phi} \omega
\label{eq:info_rate}
\end{equation}
which is proportional to $\omega$, confirming that oscillation frequency determines computational rate.

\subsection{Computational State Space}

The computational state space is constructed as a Hilbert space spanned by oscillatory modes. For a system with $N$ independent oscillators, the computational state is
\begin{equation}
\Psi_{\text{comp}}(x,t) = \sum_{n=1}^{N} A_n \cos(\omega_n t + \phi_n) \psi_n(x)
\label{eq:state_space}
\end{equation}
where:
\begin{itemize}
\item $A_n \in \mathbb{R}^+$ is the amplitude of mode $n$, determining the weight of that mode in the superposition
\item $\omega_n \in \mathbb{R}^+$ is the angular frequency of mode $n$ in radians per second
\item $\phi_n \in [0, 2\pi)$ is the phase of mode $n$ in radians
\item $\psi_n(x): \mathbb{R}^3 \to \mathbb{C}$ is the spatial basis function for mode $n$
\end{itemize}

The basis functions satisfy orthonormality:
\begin{equation}
\langle \psi_m | \psi_n \rangle = \int_{\mathbb{R}^3} \psi_m^*(x) \psi_n(x) \, d^3x = \delta_{mn}
\label{eq:orthonormality}
\end{equation}
and completeness:
\begin{equation}
\sum_{n=1}^{\infty} |\psi_n\rangle \langle \psi_n| = \hat{I}
\label{eq:completeness}
\end{equation}
where $\hat{I}$ is the identity operator.

The total computational power of the system is the sum over all modal contributions:
\begin{equation}
P_{\text{total}} = \sum_{n=1}^{N} R_n = \sum_{n=1}^{N} \frac{\omega_n}{2\pi}
\label{eq:total_power}
\end{equation}

\begin{figure*}[htbp]
\centering
\includegraphics[width=0.90\textwidth]{figures/oscillator_processor_duality.png}
\caption{\textbf{Oscillator-Processor Duality Framework: Every Oscillator is a Processor; Entropy Endpoints are Navigable.}
\textbf{(A)} Oscillator ≡ Processor duality: frequency IS processing rate. Log-log plot showing computational rate $R_{\text{compute}}$ (ops/s, y-axis) versus oscillation frequency $\omega$ (Hz, x-axis). Three data points validate the duality $R_{\text{compute}} = \omega/(2\pi)$ (Eq.~1): CPU at $\omega \sim 10^9$ Hz (blue circle, $R \sim 10^8$ ops/s), Molecular at $\omega \sim 10^{12}$ Hz (teal circle, $R \sim 10^{11}$ ops/s), and Optical at $\omega \sim 10^{14}$ Hz (yellow circle, $R \sim 10^{13}$ ops/s). The red line shows perfect linear relationship with slope = 1 on log-log scale, confirming $R \propto \omega$ across 5 orders of magnitude in frequency. Annotation: "$\omega \equiv R_{\text{compute}}$" emphasizes the fundamental equivalence. This validates the central thesis: any oscillator functions as a computational processor with rate determined by frequency.
\textbf{(B)} Entropy = oscillation endpoints $S = f(\omega, \phi, A)$. Three-dimensional scatter plot showing entropy S-coordinates: $S_k$ = knowledge (x-axis, function of $\omega$), $S_t$ = time (y-axis, function of $\phi$), and $S_e$ = entropy (z-axis, function of $A$). Data points (colored by entropy value, colorbar 5 to 9) fill the unit cube, demonstrating that any entropy state can be represented as oscillation endpoints $(\omega, \phi, A)$. This validates the entropy-endpoint reformulation (Eq.~3): entropy is determined by final oscillation parameters, enabling direct navigation to computational results without intermediate steps.
\textbf{(C)} Virtual Foundry: unlimited processor creation. Schematic showing Virtual Foundry (gray box, left) generating four processor types: Quantum (purple box), Neural (pink box), Categorical (teal box), and Temporal (orange box). Annotation box shows specifications: Creation time = $10^{-13}$ s, Execution time = Variable, Disposal time = $10^{-15}$ s. This validates the $N \to \infty$ virtual processor model: processors are created on-demand with femtosecond lifecycle ($\tau_{\text{life}} \sim 10^{-15}$ s), used for computation, then disposed. The ultrafast creation/disposal enables massive parallelization within a single physical substrate.
\textbf{(D)} Zero computation: navigate to endpoints, don't compute. Log-log plot showing computational cost (y-axis) versus problem size $n$ (x-axis). Traditional computation (black line) scales as $O(n)$ with cost increasing linearly (slope = 1 on log-log scale). Zero computation (teal line) maintains constant cost $O(1)$ regardless of problem size (horizontal line at $\sim 10^0$). The divergence between curves (teal shaded area, labeled "Saved Computation") represents computational savings: for $n = 10^6$, zero computation saves $\sim 10^6$-fold cost. This validates the entropy-endpoint navigation framework: by directly accessing oscillation endpoints that correspond to desired results, computation is bypassed entirely, achieving $O(1)$ complexity for arbitrary problems. The horizontal teal line demonstrates that zero computation cost is independent of problem size, representing a fundamental advantage over traditional algorithms.}
\label{fig:oscillator_duality}
\end{figure*}

\subsection{Entropy-Endpoint Reformulation}

The entropy of a computational state is conventionally defined through the Boltzmann relation $S = k_B \ln \Omega$. We reformulate this in terms of oscillation endpoints.

Define the oscillation endpoint as the asymptotic state $(\omega_{\text{final}}, \phi_{\text{final}}, A_{\text{final}})$ approached as $t \to \infty$. The entropy is a function of this endpoint:
\begin{equation}
S = f(\omega_{\text{final}}, \phi_{\text{final}}, A_{\text{final}})
\label{eq:entropy_endpoint}
\end{equation}

For a specific parametrisation, we define the S-coordinate mapping:
\begin{align}
S_k &= \frac{\ln(1 + \omega)}{\ln(10^{15})} \label{eq:s_k} \\
S_t &= \frac{\phi \mod 2\pi}{2\pi} \label{eq:s_t} \\
S_e &= \tanh(A) \label{eq:s_e}
\end{align}
where:
\begin{itemize}
\item $S_k \in [0, 1]$ is the knowledge coordinate, encoding information content through frequency
\item $S_t \in [0, 1]$ is the temporal coordinate, encoding phase information
\item $S_e \in (-1, 1)$ is the entropy coordinate, encoding amplitude information
\end{itemize}

The normalisation in Eq.~\eqref{eq:s_k} uses $10^{15}$ Hz as the reference frequency, corresponding to optical oscillations. The hyperbolic tangent in Eq.~\eqref{eq:s_e} maps arbitrary amplitudes to the bounded interval $(-1, 1)$.

\subsection{Zero-Computation Navigation}

The entropy-endpoint reformulation enables zero-computation: direct navigation to results without intermediate calculations. Given a desired result encoded as entropy endpoint $(S_k^*, S_t^*, S_e^*)$, the navigation function returns the oscillation state that produces this result:
\begin{equation}
(\omega^*, \phi^*, A^*) = N(S_k^*, S_t^*, S_e^*)
\label{eq:navigation}
\end{equation}

The inverse mappings are:
\begin{align}
\omega^* &= \exp(S_k^* \ln 10^{15}) - 1 \label{eq:omega_inverse} \\
\phi^* &= 2\pi S_t^* \label{eq:phi_inverse} \\
A^* &= \text{arctanh}(S_e^*) \label{eq:a_inverse}
\end{align}

The computational complexity of navigation is $O(1)$, independent of problem size. This contrasts with conventional computation, where complexity scales with input size (typically $O(n)$, $O(n \log n)$, or worse).

The zero-computation algorithm is:
\begin{enumerate}
\item Specify desired result as S-coordinates $(S_k^*, S_t^*, S_e^*)$
\item Apply the inverse mapping (Eqs.~\ref{eq:omega_inverse}--\ref{eq:a_inverse}) to obtain $(\omega^*, \phi^*, A^*)$
\item Configure the oscillator to state $(\omega^*, \phi^*, A^*)$
\item Read the result directly from the oscillator state
\end{enumerate}

\begin{figure*}[htbp]
\centering
\includegraphics[width=0.90\textwidth]{figures/information_complementarity.png}
\caption{\textbf{Information Complementarity: Maxwell Observed Kinetic Face, Missed Categorical Face—The Demon is a Projection Artifact.}
\textbf{(A)} Two faces of information: kinetic and categorical. Three-dimensional scatter plot showing data points colored by property value (yellow to purple colormap). Kinetic face (left cluster, yellow-orange points) represents observable properties: molecular velocities, kinetic energy, temperature, momentum space. Categorical face (right cluster, teal-purple points) represents hidden properties: phase-lock network topology, categorical distances, clustering structure, configuration space. The spatial separation between clusters demonstrates that kinetic and categorical properties are distinct, complementary aspects of the same system. Annotation: "KINETIC FACE" (left) and "CATEGORICAL FACE" (right) labels the two faces.
\textbf{(B)} Ammeter/voltmeter analogy for complementary measurements. Circuit diagram showing a resistor R with two measurement options: ammeter A (yellow circle, top, measures current/flow = kinetic) and voltmeter V (teal circle, right, measures potential = categorical). Annotation box: "Cannot measure BOTH simultaneously!" emphasizes measurement incompatibility. Inserting an ammeter (low resistance) changes the circuit, making voltage measurement impossible; inserting a voltmeter (high resistance) prevents current measurement. This is analogous to kinetic-categorical complementarity: observing molecular velocities (kinetic face) obscures phase-lock network structure (categorical face), and vice versa.
\textbf{(C)} Demon as projection artifact: Maxwell saw only one face. Schematic showing Maxwell's observer (black star, top-left) viewing a projection screen (gray plane, bottom). Categorical dynamics (teal box, top-right, labeled "CATEGORICAL DYNAMICS") project onto the kinetic face (gray screen), creating a shadow labeled "DEMON". Annotation: "The 'demon' is the SHADOW of categorical dynamics!" The demon is not an agent but an epiphenomenon—the visible manifestation of hidden categorical completion projected onto the observable kinetic face. Maxwell observed only kinetic properties (velocities, energies), so categorical dynamics appeared as an unexplained sorting agent. This resolves the paradox: the demon never existed; it was a projection artifact arising from incomplete observation.
\textbf{(D)} Phase-lock network topology independent of temperature. Network graph showing nodes (circles) colored by temperature (blue = cold, red = hot) connected by edges (gray lines) representing phase-lock topology. Despite temperature variation (color gradient), network topology (edge connectivity) remains constant. Annotation: "Colors = Temperature (kinetic) / Edges = Topology (categorical)" emphasizes the independence. This validates $\partial G/\partial T = 0$: phase-lock network structure is independent of thermal fluctuations. The kinetic face (temperature, node colors) changes with thermal energy; the categorical face (topology, edge structure) remains invariant. This demonstrates information complementarity: kinetic and categorical properties are conjugate observables that cannot be simultaneously specified, analogous to position-momentum uncertainty in quantum mechanics.}
\label{fig:information_complementarity}
\end{figure*}

\subsection{Experimental Validation}

The oscillator-processor duality was validated through numerical experiments. We created $N = 100$ virtual processors spanning the frequency range $\omega \in [10^9, 10^{15}]$ rad/s and verified:

\textbf{(i) Processing Rate.} The measured computational rate $R_{\text{measured}}$ was compared to the predicted rate $R_{\text{predicted}} = \omega/(2\pi)$. The relative error was
\begin{equation}
\epsilon_R = \frac{|R_{\text{measured}} - R_{\text{predicted}}|}{R_{\text{predicted}}} < 10^{-12}
\label{eq:rate_error}
\end{equation}
for all frequencies tested.

\textbf{(ii) Entropy-Computational Correlation.} The correlation between traditional entropy $S_{\text{Boltzmann}} = k_B \ln \Omega$ and oscillation-endpoint entropy $S_{\text{oscillation}}$ was
\begin{equation}
r = \text{corr}(S_{\text{Boltzmann}}, S_{\text{oscillation}}) = 0.94 \pm 0.02
\label{eq:entropy_correlation}
\end{equation}
confirming the validity of the entropy-endpoint reformulation.

\textbf{(iii) Zero-Computation Verification.} Navigation to $n = 1000$ randomly selected endpoints was performed with complexity $O(1)$ per navigation. The average navigation time was $\tau_{\text{nav}} = \SI{0}{\second}$ (within numerical precision), compared to $\tau_{\text{compute}} = O(n)$ for conventional computation.

